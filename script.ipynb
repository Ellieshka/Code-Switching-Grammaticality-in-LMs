{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9a3465",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded file\n",
    "stimuli = pd.read_csv(r\"C:\\Users\\lisus\\Downloads\\stimuli.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Changing into long format for surprisal computing\n",
    "long_stimuli = stimuli.melt(\n",
    "    stimuli,\n",
    "    id_vars=[\"phenomenon\", \"pair_id\"],\n",
    "    value_vars=[\"spa_eng_grammatical\", \"spa_eng_ungrammatical\",\n",
    "                \"eng_spa_grammatical\", \"eng_spa_ungrammatical\"],\n",
    "    var_name=\"condition\",\n",
    "    value_name=\"sentence\"\n",
    ")\n",
    "\n",
    "# Creating labels\n",
    "long_stimuli[\"label\"] = (\n",
    "    long_stimuli[\"phenomenon\"] + \"_\" +\n",
    "    long_stimuli[\"pair_id\"].astype(str) + \"_\" +\n",
    "    long_stimuli[\"condition\"]\n",
    ")\n",
    "\n",
    "# Showing two columns for MINICONS code\n",
    "input = long_stimuli[[\"label\", \"sentence\"]]\n",
    "\n",
    "# Save to CSV for MINICONS\n",
    "input.to_csv(\"input_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6dd73",
   "metadata": {},
   "source": [
    "Surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minicons import scorer\n",
    "\n",
    "input = pd.read_csv(r\"C:\\Users\\lisus\\Downloads\\input.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Loading the minicons model\n",
    "model = scorer.MaskedLMScorer(\"xlm-roberta-base\", device=\"cpu\")\n",
    "\n",
    "# Extract the sentences from data and store in Python memory\n",
    "sentences = stimuli.iloc[:, 1].tolist()\n",
    "\n",
    "# Processing data in chunks\n",
    "batch_size = 50\n",
    "\n",
    "# Creating a new list to add processed data to\n",
    "sequence_scores = []\n",
    "\n",
    "# Appending each batch to the list in a loop sequence\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    batch = sentences[i:i+batch_size]\n",
    "    # Computing surprisal scores\n",
    "    scores = model.sequence_score(batch, reduction=lambda x: -x.sum(0).item())\n",
    "    sequence_scores.extend(scores)\n",
    "\n",
    "# Attach results back to your dataframe\n",
    "input[\"surprisal\"] = sequence_scores\n",
    "\n",
    "# Saving the results to a new CSV file\n",
    "input.to_csv(\"surprisal_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cdf8a5",
   "metadata": {},
   "source": [
    "Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68420df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv(r\"C:\\Users\\lisus\\Downloads\\reshaped_surprisal_output.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Checking whether the model assigns lower surpirsal to the grammatical sentence\n",
    "def prefers_grammatical(group):\n",
    "    gram = group.loc[group[\"grammaticality\"] == \"grammatical\", \"surprisal\"].values[0]\n",
    "    ungram = group.loc[group[\"grammaticality\"] == \"ungrammatical\", \"surprisal\"].values[0]\n",
    "    return gram < ungram\n",
    "\n",
    "# Computing preference per pair\n",
    "accuracy_scores = output.groupby(\n",
    "    [\"phenomenon\", \"sentence_number\"]\n",
    ").apply(prefers_grammatical)\n",
    "\n",
    "# Adding a column for the pair preference\n",
    "accuracy_scores[\"prefers_gram\"] = output.set_index(\n",
    "    [\"phenomenon\", \"sentence_number\"]\n",
    ").index.map(preference)\n",
    "\n",
    "# Computing accuracy per phenomenon\n",
    "results = output.groupby(\"phenomenon\")[\"prefers_gram\"].mean()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb84542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing accuracy per codeswitch direction\n",
    "preference_by_language = output.groupby(\n",
    "    [\"phenomenon\", \"codeswitch_direction\"]\n",
    ")[\"prefers_gram\"].mean()\n",
    "\n",
    "print(preference_by_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62605e45",
   "metadata": {},
   "source": [
    "Plot: Surprisal Distributions by Code-Switch Directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Boxplot: surprisal by direction and grammaticality\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(\n",
    "    data=output,\n",
    "    x=\"codeswitch_direction\",\n",
    "    y=\"surprisal\",\n",
    "    hue=\"grammaticality\"\n",
    ")\n",
    "plt.title(\"Surprisal distributions by code-switch direction\")\n",
    "plt.ylabel(\"Surprisal\")\n",
    "plt.xlabel(\"Direction\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
